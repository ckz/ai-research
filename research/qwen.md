# Qwen

## Company Overview
| Attribute | Details |
|-----------|---------|
| **Company Name** | Qwen (Tongyi Qianwen) |
| **Parent Company** | Alibaba Cloud |
| **Launched** | 2023 |
| **Headquarters** | Hangzhou, China |
| **Category** | Foundation AI Models |
| **One-Sentence Description** | Alibaba's open-source LLM family with 600M+ downloads, 170K+ derivative models, and 30M+ MAU - fastest-growing AI app globally in November 2025 |

## Parent Company
- **Alibaba Cloud** (Alibaba Group subsidiary)
- Alibaba Group: NYSE: BABA, HKEX: 9988
- Leading Chinese cloud provider

## Key Metrics
- **Downloads**: 600+ million (cumulative)
- **Derivative Models**: 170,000+ created by developers
- **Enterprise Users**: 90,000+ via Model Studio
- **Individual/Corporate Users**: 1 million+ on Model Studio
- **App MAU**: 30+ million (achieved in 23 days after public beta)
- **App Downloads**: 10 million in first week of public beta
- **November 2025 Growth**: 149% MAU increase (18.34M MAU)
- **Ranking**: #1 fastest-growing AI app globally (Nov 2025)

## Investment
- **3-Year Commitment**: $53 billion in cloud and AI infrastructure (Feb 2025)
- **AI Revenue Growth**: Triple-digit growth for 8 consecutive quarters
- **AI Revenue Share**: 20%+ of cloud external customer revenue

## Model Versions

### Qwen 3 Family (April 2025)
| Model | Parameters | Notes |
|-------|------------|-------|
| Qwen3-0.6B | 0.6B | Smallest |
| Qwen3-1.7B | 1.7B | - |
| Qwen3-4B | 4B | - |
| Qwen3-8B | 8B | - |
| Qwen3-14B | 14B | - |
| Qwen3-32B | 32B | Dense |
| Qwen3-30B-A3B | 30B (3B active) | MoE |
| Qwen3-235B-A22B | 235B (22B active) | MoE, flagship |

### Training
- **Data**: 36 trillion tokens
- **Languages**: 119 languages and dialects
- **License**: Apache 2.0 (open source)

### Key Releases
- **Qwen2.5-Max** (January 2025): Outperforms GPT-4o, DeepSeek-V3
- **Qwen3** (April 2025): Full model family release
- **Qwen3-Max** (September 2025): Outperforms Claude 4 Opus, Kimi K2

## Products & Features

### Model Capabilities
- Text generation
- Code generation
- Mathematical reasoning
- Multilingual support
- Tool use
- Long context (up to 128K tokens)

### Platforms
- Alibaba Cloud Model Studio
- Hugging Face
- GitHub
- Direct API access

## Pricing
- Open-source models: Free
- API access via Model Studio: Usage-based
- Enterprise deployment: Custom

## Target Users
- AI developers
- Researchers
- Enterprise customers
- Startups building on LLMs
- Chinese and global markets

## Competitive Position
Competing with:
- OpenAI GPT models
- Meta Llama
- Google Gemini
- DeepSeek
- Anthropic Claude
- Mistral

### Competitive Advantages
- Open source (Apache 2.0)
- 600M+ downloads
- Strong performance vs. closed models
- Multilingual (119 languages)
- Alibaba Cloud integration
- Active developer community

## Recognition
- **Fortune 2025 Change the World List**: Recognized for open-source AI commitment
- Over 300 generative AI models open-sourced

## Strategic Notes
- Open-source strategy differentiates from OpenAI
- 600M downloads demonstrates global adoption
- $53B investment shows long-term commitment
- Competing globally despite China origin
- 149% MAU growth shows explosive consumer adoption
- Model Studio creates enterprise revenue
- Apache 2.0 license enables commercial use
- Performance competitive with GPT-4, Claude

## Status
Active - Leading open-source LLM from China

## Sources
- Alibaba Cloud, Hugging Face, Alizila, Fortune, Chinese tech media
